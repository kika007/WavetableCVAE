

hydra:
  run:
    dir: ./log/hydra/${model._target_}/${now:%Y%m%d}T${now:%H%M%S}-${trainer.max_epochs}epoch
  sweep:
    dir: ./log/hydra/${model._target_}/${now:%Y%m%d}T${now:%H%M%S}-${trainer.max_epochs}epoch

model:
  _target_: "src.models.cvae.LitCVAE"
  enc_cond_layer: [True, True, True, True] # [Falase, False, False, False]
  dec_cond_layer: [True, True, True, True]  # [True, False, False, False]
  enc_channels: [64, 128, 256, 512]
  latent_dim: 256  # 128
  dec_channels: [128, 64, 32, 16]   # [64, 32, 16, 8]
  beta: 0
  duplicate_num: 6
  sample_points: 600
  sample_rate: 44100
  lr: 1e-5
  wave_loss_coef: null

datamodule:
  _target_: "src.dataio.akwd_datamodule.AWKDDataModule"
  batch_size: 32

logger:
  _target_: pytorch_lightning.loggers.wandb.WandbLogger
  save_dir: null # "${paths.output_dir}"
  offline: False
  id: null # pass correct id to resume experiment!
  anonymous: null # enable anonymous logging
  project: 'WavetableCVAE'
  log_model: True # upload lightning ckpts
  prefix: "" # a string to put at the beginning of metric keys
  # entity: "" # set to name of your wandb team
  group: ""
  tags: []
  job_type: ""

trainer:
  _target_: pytorch_lightning.Trainer
  max_epochs: 2001
  enable_checkpointing: True
  auto_lr_find: True
  auto_scale_batch_size: True

callbacks:
  _target_: "src.models.components.callback.MyPrintingCallback"

resume: null  # "/workspace/My-reserch-project/WavetableCVAE/rp6j1uld/checkpoints/epoch=1999-step=198000.ckpt"
save: False
seed: 42
debug_mode: False